# -*- coding: utf-8 -*-
"""taste_Bi-LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cK6STTb9TbXzu2e_icmoAiqRlPOiCxSg
"""

from google.colab import drive
drive.mount('/content/drive')

import scipy.io
import os
import numpy as np
import pandas as pd

folder_path = '/content/drive/My Drive/taste_datasets'  # Update as needed
files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]

all_segments = []
all_labels = []
label_log = []  # To track filename and assigned label per segment

for fname in files:
    data = scipy.io.loadmat(os.path.join(folder_path, fname))

    # Check variable names as saved from MATLAB
    if 'segments_permuted' in data and 'labels' in data:
        segments = data['segments_permuted']  # shape: (segments, time_steps, channels)
        labels = data['labels'].flatten()     # typically MATLAB cell array

        # Convert MATLAB cell to list of strings
        labels_list = [str(l[0]) if isinstance(l, np.ndarray) else str(l) for l in labels]
        labels_list = ['Sweet' if label == 'Sugar' else label for label in labels_list]

        all_segments.append(segments)
        all_labels.extend(labels_list)
        for segment_label in labels_list:
            label_log.append({'filename': fname, 'label': segment_label})
    else:
        print(f"Warning: {fname} missing 'segments_permuted' or 'labels', skipping.")

# After processing all files, concatenate all segments
all_segments = np.concatenate(all_segments, axis=0)

# Convert labels list to numpy array of dtype object (for saving)
all_labels = np.array(all_labels, dtype=object)

# Save combined arrays as a new .mat file
scipy.io.savemat('All_Preprocessed_fNIRS.mat',
                 {'all_segments': all_segments, 'all_labels': all_labels})

label_log_df = pd.DataFrame(label_log)
label_log_df.to_csv('label_mapping_log.csv', index=False)


print(f"Total segments combined: {all_segments.shape[0]}")
print(f"Shape of all_segments: {all_segments.shape}")
print(f"Number of labels: {len(all_labels)}")
print(f"Label log saved as 'label_mapping_log.csv'")

data = scipy.io.loadmat('All_Preprocessed_fNIRS.mat')

X = data['all_segments']  # shape: (samples, time_steps, channels)
labels = data['all_labels'].flatten()  # flatten to 1D array if needed

# Convert MATLAB cells or bytes to strings
labels = [str(l[0]) if (isinstance(l, np.ndarray) or isinstance(l, bytes)) else str(l) for l in labels]

print(f"Data shape: {X.shape}")
print(f"Number of labels: {len(labels)}")
print(f"Classes: {set(labels)}")

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

le = LabelEncoder()
y_int = le.fit_transform(labels)   # Convert string labels to integers
y_cat = to_categorical(y_int)      # One-hot encoding

print(f"Label classes: {le.classes_}")
print(f"One-hot label shape: {y_cat.shape}")

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X, y_cat, test_size=0.2, random_state=42, stratify=y_int)

print(f"Training samples: {X_train.shape[0]}, Validation samples: {X_val.shape[0]}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense

model = Sequential([
    Bidirectional(LSTM(64, return_sequences=True), input_shape=(X.shape[1], X.shape[2])),
    Dropout(0.2),
    Bidirectional(LSTM(32)),
    Dropout(0.2),
    Dense(y_cat.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

import matplotlib.pyplot as plt

history = model.fit(
    X_train, y_train,
    epochs=40,
    batch_size=32,
    validation_data=(X_val, y_val)
)

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from itertools import cycle

# 1. Get predicted probabilities and predicted classes
y_pred_probs = model.predict(X_val)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_val, axis=1)

# 2. Print classification report (precision, recall, f1-score)
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=le.classes_))

# 3. Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# 4. Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(le.classes_))
plt.xticks(tick_marks, le.classes_, rotation=45)
plt.yticks(tick_marks, le.classes_)

# Annotate each cell with counts
thresh = cm.max() / 2
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment='center',
                 color='white' if cm[i, j] > thresh else 'black')

plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

# 5. Plot ROC curves and compute AUC for each class (one-vs-rest)
n_classes = y_val.shape[1]
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], y_pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(10, 8))
colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'ROC curve of class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)  # diagonal line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves (One-vs-Rest)')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

print("Max training accuracy over epochs:", max(history.history['accuracy']))
print("Max validation accuracy over epochs:", max(history.history['val_accuracy']))

model.save('fNIRS_transformer_model.h5')